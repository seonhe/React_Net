{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# DataLoader Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/neungyun/anaconda3/envs/torch/lib/python3.8/site-packages/pytorch_lightning/core/datamodule.py:73: LightningDeprecationWarning: DataModule property `train_transforms` was deprecated in v1.5 and will be removed in v1.7.\n",
      "  rank_zero_deprecation(\n",
      "/home/neungyun/anaconda3/envs/torch/lib/python3.8/site-packages/pytorch_lightning/core/datamodule.py:77: LightningDeprecationWarning: DataModule property `val_transforms` was deprecated in v1.5 and will be removed in v1.7.\n",
      "  rank_zero_deprecation(\n",
      "/home/neungyun/anaconda3/envs/torch/lib/python3.8/site-packages/pytorch_lightning/core/datamodule.py:81: LightningDeprecationWarning: DataModule property `test_transforms` was deprecated in v1.5 and will be removed in v1.7.\n",
      "  rank_zero_deprecation(\n",
      "Global seed set to 1234\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "1234"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import os\n",
    "import torch\n",
    "import torchvision\n",
    "from pytorch_lightning import seed_everything\n",
    "from pl_bolts.datamodules import CIFAR10DataModule, TinyCIFAR10DataModule\n",
    "from pl_bolts.transforms.dataset_normalizations import cifar10_normalization\n",
    "\n",
    "PATH_DATASETS = os.environ.get('PATH_DATASETS', '../datasets')\n",
    "AVAIL_GPUS = min(1, torch.cuda.device_count())\n",
    "BATCH_SIZE = 512 if AVAIL_GPUS else 64\n",
    "NUM_WORKERS = int(os.cpu_count()/2)\n",
    "TEST_ONLY = False\n",
    "\n",
    "test_transforms = [\n",
    "        torchvision.transforms.ToTensor(),\n",
    "        cifar10_normalization(),        \n",
    "        torchvision.transforms.Lambda(lambda x: x.clamp(min = -1, max = 1)),\n",
    "        torchvision.transforms.Lambda(lambda x: x * 127),   \n",
    "        torchvision.transforms.Lambda(lambda x: x.floor())  \n",
    "]\n",
    "\n",
    "train_transforms = torchvision.transforms.Compose(\n",
    "    [\n",
    "        torchvision.transforms.RandomCrop(32, padding=4),\n",
    "        torchvision.transforms.RandomHorizontalFlip(),\n",
    "    ] \n",
    "    + test_transforms\n",
    ")\n",
    "\n",
    "test_transforms = torchvision.transforms.Compose(test_transforms)\n",
    "\n",
    "cifar10_dm = CIFAR10DataModule(\n",
    "    data_dir = PATH_DATASETS,\n",
    "    batch_size = BATCH_SIZE,\n",
    "    num_workers = NUM_WORKERS,\n",
    "    train_transforms = train_transforms,\n",
    "    test_transforms = test_transforms,\n",
    "    val_transforms = test_transforms,\n",
    ")\n",
    "\n",
    "seed_everything(seed=1234, workers=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# model "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "BaselineModel(\n",
      "  (base_block): ModuleList(\n",
      "    (0): Base_Normal_Block(\n",
      "      (layer1): Sequential(\n",
      "        (0): Sign(out_channels=3)\n",
      "        (1): Conv2d(3, 3, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "        (2): BatchNorm2d(3, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      )\n",
      "      (layer2): Sequential(\n",
      "        (0): Sign(out_channels=3)\n",
      "        (1): Conv2d(3, 3, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (2): BatchNorm2d(3, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      )\n",
      "    )\n",
      "    (1): Base_Reduction_Block(\n",
      "      (layer1): Sequential(\n",
      "        (0): Sign(out_channels=3)\n",
      "        (1): Conv2d(3, 3, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
      "        (2): BatchNorm2d(3, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      )\n",
      "      (layer2_1): Sequential(\n",
      "        (0): Sign(out_channels=3)\n",
      "        (1): Conv2d(3, 3, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (2): BatchNorm2d(3, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      )\n",
      "      (layer2_2): Sequential(\n",
      "        (0): Sign(out_channels=3)\n",
      "        (1): Conv2d(3, 3, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (2): BatchNorm2d(3, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      )\n",
      "      (pool): AvgPool2d(kernel_size=2, stride=2, padding=0)\n",
      "    )\n",
      "    (2): Base_Reduction_Block(\n",
      "      (layer1): Sequential(\n",
      "        (0): Sign(out_channels=6)\n",
      "        (1): Conv2d(6, 6, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
      "        (2): BatchNorm2d(6, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      )\n",
      "      (layer2_1): Sequential(\n",
      "        (0): Sign(out_channels=6)\n",
      "        (1): Conv2d(6, 6, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (2): BatchNorm2d(6, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      )\n",
      "      (layer2_2): Sequential(\n",
      "        (0): Sign(out_channels=6)\n",
      "        (1): Conv2d(6, 6, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (2): BatchNorm2d(6, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      )\n",
      "      (pool): AvgPool2d(kernel_size=2, stride=2, padding=0)\n",
      "    )\n",
      "    (3): Base_Reduction_Block(\n",
      "      (layer1): Sequential(\n",
      "        (0): Sign(out_channels=6)\n",
      "        (1): Conv2d(6, 6, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
      "        (2): BatchNorm2d(6, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      )\n",
      "      (layer2_1): Sequential(\n",
      "        (0): Sign(out_channels=6)\n",
      "        (1): Conv2d(6, 6, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (2): BatchNorm2d(6, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      )\n",
      "      (layer2_2): Sequential(\n",
      "        (0): Sign(out_channels=6)\n",
      "        (1): Conv2d(6, 6, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (2): BatchNorm2d(6, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      )\n",
      "      (pool): AvgPool2d(kernel_size=2, stride=2, padding=0)\n",
      "    )\n",
      "    (4): Base_Reduction_Block(\n",
      "      (layer1): Sequential(\n",
      "        (0): Sign(out_channels=12)\n",
      "        (1): Conv2d(12, 12, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
      "        (2): BatchNorm2d(12, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      )\n",
      "      (layer2_1): Sequential(\n",
      "        (0): Sign(out_channels=12)\n",
      "        (1): Conv2d(12, 12, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (2): BatchNorm2d(12, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      )\n",
      "      (layer2_2): Sequential(\n",
      "        (0): Sign(out_channels=12)\n",
      "        (1): Conv2d(12, 12, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (2): BatchNorm2d(12, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      )\n",
      "      (pool): AvgPool2d(kernel_size=2, stride=2, padding=0)\n",
      "    )\n",
      "    (5): Base_Reduction_Block(\n",
      "      (layer1): Sequential(\n",
      "        (0): Sign(out_channels=12)\n",
      "        (1): Conv2d(12, 12, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
      "        (2): BatchNorm2d(12, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      )\n",
      "      (layer2_1): Sequential(\n",
      "        (0): Sign(out_channels=12)\n",
      "        (1): Conv2d(12, 12, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (2): BatchNorm2d(12, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      )\n",
      "      (layer2_2): Sequential(\n",
      "        (0): Sign(out_channels=12)\n",
      "        (1): Conv2d(12, 12, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (2): BatchNorm2d(12, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      )\n",
      "      (pool): AvgPool2d(kernel_size=2, stride=2, padding=0)\n",
      "    )\n",
      "    (6): Base_Reduction_Block(\n",
      "      (layer1): Sequential(\n",
      "        (0): Sign(out_channels=24)\n",
      "        (1): Conv2d(24, 24, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
      "        (2): BatchNorm2d(24, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      )\n",
      "      (layer2_1): Sequential(\n",
      "        (0): Sign(out_channels=24)\n",
      "        (1): Conv2d(24, 24, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (2): BatchNorm2d(24, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      )\n",
      "      (layer2_2): Sequential(\n",
      "        (0): Sign(out_channels=24)\n",
      "        (1): Conv2d(24, 24, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (2): BatchNorm2d(24, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      )\n",
      "      (pool): AvgPool2d(kernel_size=2, stride=2, padding=0)\n",
      "    )\n",
      "    (7): Base_Reduction_Block(\n",
      "      (layer1): Sequential(\n",
      "        (0): Sign(out_channels=24)\n",
      "        (1): Conv2d(24, 24, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
      "        (2): BatchNorm2d(24, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      )\n",
      "      (layer2_1): Sequential(\n",
      "        (0): Sign(out_channels=24)\n",
      "        (1): Conv2d(24, 24, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (2): BatchNorm2d(24, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      )\n",
      "      (layer2_2): Sequential(\n",
      "        (0): Sign(out_channels=24)\n",
      "        (1): Conv2d(24, 24, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (2): BatchNorm2d(24, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      )\n",
      "      (pool): AvgPool2d(kernel_size=2, stride=2, padding=0)\n",
      "    )\n",
      "    (8): Base_Reduction_Block(\n",
      "      (layer1): Sequential(\n",
      "        (0): Sign(out_channels=48)\n",
      "        (1): Conv2d(48, 48, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
      "        (2): BatchNorm2d(48, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      )\n",
      "      (layer2_1): Sequential(\n",
      "        (0): Sign(out_channels=48)\n",
      "        (1): Conv2d(48, 48, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (2): BatchNorm2d(48, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      )\n",
      "      (layer2_2): Sequential(\n",
      "        (0): Sign(out_channels=48)\n",
      "        (1): Conv2d(48, 48, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (2): BatchNorm2d(48, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      )\n",
      "      (pool): AvgPool2d(kernel_size=2, stride=2, padding=0)\n",
      "    )\n",
      "    (9): Base_Reduction_Block(\n",
      "      (layer1): Sequential(\n",
      "        (0): Sign(out_channels=48)\n",
      "        (1): Conv2d(48, 48, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
      "        (2): BatchNorm2d(48, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      )\n",
      "      (layer2_1): Sequential(\n",
      "        (0): Sign(out_channels=48)\n",
      "        (1): Conv2d(48, 48, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (2): BatchNorm2d(48, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      )\n",
      "      (layer2_2): Sequential(\n",
      "        (0): Sign(out_channels=48)\n",
      "        (1): Conv2d(48, 48, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (2): BatchNorm2d(48, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      )\n",
      "      (pool): AvgPool2d(kernel_size=2, stride=2, padding=0)\n",
      "    )\n",
      "    (10): Base_Reduction_Block(\n",
      "      (layer1): Sequential(\n",
      "        (0): Sign(out_channels=96)\n",
      "        (1): Conv2d(96, 96, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
      "        (2): BatchNorm2d(96, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      )\n",
      "      (layer2_1): Sequential(\n",
      "        (0): Sign(out_channels=96)\n",
      "        (1): Conv2d(96, 96, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (2): BatchNorm2d(96, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      )\n",
      "      (layer2_2): Sequential(\n",
      "        (0): Sign(out_channels=96)\n",
      "        (1): Conv2d(96, 96, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (2): BatchNorm2d(96, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      )\n",
      "      (pool): AvgPool2d(kernel_size=2, stride=2, padding=0)\n",
      "    )\n",
      "    (11): Base_Reduction_Block(\n",
      "      (layer1): Sequential(\n",
      "        (0): Sign(out_channels=96)\n",
      "        (1): Conv2d(96, 96, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
      "        (2): BatchNorm2d(96, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      )\n",
      "      (layer2_1): Sequential(\n",
      "        (0): Sign(out_channels=96)\n",
      "        (1): Conv2d(96, 96, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (2): BatchNorm2d(96, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      )\n",
      "      (layer2_2): Sequential(\n",
      "        (0): Sign(out_channels=96)\n",
      "        (1): Conv2d(96, 96, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (2): BatchNorm2d(96, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      )\n",
      "      (pool): AvgPool2d(kernel_size=2, stride=2, padding=0)\n",
      "    )\n",
      "  )\n",
      ")\n",
      "\"adam_betas\":        (0.9, 0.999)\n",
      "\"adam_init_lr\":      0.01\n",
      "\"adam_weight_decay\": 0\n",
      "\"channel_array\":     [3, 3, 6, 6, 12, 12, 24, 24, 48, 48, 96, 96]\n",
      "\"limit_bn_weight\":   True\n",
      "\"limit_conv_weight\": True\n",
      "\"lr_patience\":       50\n",
      "\"lr_reduce_factor\":  0.1\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import pytorch_lightning as pl\n",
    "from model import BaselineModel\n",
    "\n",
    "channel_array = [3, 3, 6, 6, 12, 12, 24, 24, 48, 48, 96, 96]\n",
    "\n",
    "base_model = BaselineModel(channel_array)\n",
    "print(base_model)\n",
    "print(base_model.hparams)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "GPU available: True, used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "IPU available: False, using: 0 IPUs\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading https://www.cs.toronto.edu/~kriz/cifar-10-python.tar.gz to ../datasets/cifar-10-python.tar.gz\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "013949a1045f43dfb53e6ca5fe41af81",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/170498071 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting ../datasets/cifar-10-python.tar.gz to ../datasets\n",
      "Files already downloaded and verified\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/neungyun/anaconda3/envs/torch/lib/python3.8/site-packages/pytorch_lightning/core/datamodule.py:114: LightningDeprecationWarning: DataModule property `train_transforms` was deprecated in v1.5 and will be removed in v1.7.\n",
      "  rank_zero_deprecation(\n",
      "/home/neungyun/anaconda3/envs/torch/lib/python3.8/site-packages/pytorch_lightning/core/datamodule.py:133: LightningDeprecationWarning: DataModule property `val_transforms` was deprecated in v1.5 and will be removed in v1.7.\n",
      "  rank_zero_deprecation(\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n",
      "/home/neungyun/anaconda3/envs/torch/lib/python3.8/site-packages/torch/_jit_internal.py:668: LightningDeprecationWarning: The `LightningModule.loaded_optimizer_states_dict` property is deprecated in v1.4 and will be removed in v1.6.\n",
      "  if hasattr(mod, name):\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Error occurs, No graph saved\n"
     ]
    },
    {
     "ename": "NotImplementedError",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNotImplementedError\u001b[0m                       Traceback (most recent call last)",
      "\u001b[1;32m/home/neungyun/React_Net/main.ipynb Cell 5'\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      <a href='vscode-notebook-cell://wsl%2Bubuntu/home/neungyun/React_Net/main.ipynb#ch0000001vscode-remote?line=6'>7</a>\u001b[0m checkpoint_callback \u001b[39m=\u001b[39m ModelCheckpoint(filename\u001b[39m=\u001b[39m\u001b[39m'\u001b[39m\u001b[39m{epoch}\u001b[39;00m\u001b[39m-\u001b[39m\u001b[39m{val_loss:.4f}\u001b[39;00m\u001b[39m-\u001b[39m\u001b[39m{val_acc:.4f}\u001b[39;00m\u001b[39m'\u001b[39m, monitor\u001b[39m=\u001b[39m\u001b[39m'\u001b[39m\u001b[39mval_acc\u001b[39m\u001b[39m'\u001b[39m, mode\u001b[39m=\u001b[39m\u001b[39m'\u001b[39m\u001b[39mmax\u001b[39m\u001b[39m'\u001b[39m)\n\u001b[1;32m      <a href='vscode-notebook-cell://wsl%2Bubuntu/home/neungyun/React_Net/main.ipynb#ch0000001vscode-remote?line=7'>8</a>\u001b[0m trainer \u001b[39m=\u001b[39m Trainer(\n\u001b[1;32m      <a href='vscode-notebook-cell://wsl%2Bubuntu/home/neungyun/React_Net/main.ipynb#ch0000001vscode-remote?line=8'>9</a>\u001b[0m     max_epochs\u001b[39m=\u001b[39m\u001b[39m-\u001b[39m\u001b[39m1\u001b[39m,\n\u001b[1;32m     <a href='vscode-notebook-cell://wsl%2Bubuntu/home/neungyun/React_Net/main.ipynb#ch0000001vscode-remote?line=9'>10</a>\u001b[0m     gpus\u001b[39m=\u001b[39mAVAIL_GPUS,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m     <a href='vscode-notebook-cell://wsl%2Bubuntu/home/neungyun/React_Net/main.ipynb#ch0000001vscode-remote?line=16'>17</a>\u001b[0m \u001b[39m#    gradient_clip_val = 0.5\u001b[39;00m\n\u001b[1;32m     <a href='vscode-notebook-cell://wsl%2Bubuntu/home/neungyun/React_Net/main.ipynb#ch0000001vscode-remote?line=17'>18</a>\u001b[0m )\n\u001b[0;32m---> <a href='vscode-notebook-cell://wsl%2Bubuntu/home/neungyun/React_Net/main.ipynb#ch0000001vscode-remote?line=19'>20</a>\u001b[0m trainer\u001b[39m.\u001b[39;49mfit(base_model, datamodule\u001b[39m=\u001b[39;49mcifar10_dm)\n",
      "File \u001b[0;32m~/anaconda3/envs/torch/lib/python3.8/site-packages/pytorch_lightning/trainer/trainer.py:740\u001b[0m, in \u001b[0;36mTrainer.fit\u001b[0;34m(self, model, train_dataloaders, val_dataloaders, datamodule, train_dataloader, ckpt_path)\u001b[0m\n\u001b[1;32m    <a href='file:///~/anaconda3/envs/torch/lib/python3.8/site-packages/pytorch_lightning/trainer/trainer.py?line=734'>735</a>\u001b[0m     rank_zero_deprecation(\n\u001b[1;32m    <a href='file:///~/anaconda3/envs/torch/lib/python3.8/site-packages/pytorch_lightning/trainer/trainer.py?line=735'>736</a>\u001b[0m         \u001b[39m\"\u001b[39m\u001b[39m`trainer.fit(train_dataloader)` is deprecated in v1.4 and will be removed in v1.6.\u001b[39m\u001b[39m\"\u001b[39m\n\u001b[1;32m    <a href='file:///~/anaconda3/envs/torch/lib/python3.8/site-packages/pytorch_lightning/trainer/trainer.py?line=736'>737</a>\u001b[0m         \u001b[39m\"\u001b[39m\u001b[39m Use `trainer.fit(train_dataloaders)` instead. HINT: added \u001b[39m\u001b[39m'\u001b[39m\u001b[39ms\u001b[39m\u001b[39m'\u001b[39m\u001b[39m\"\u001b[39m\n\u001b[1;32m    <a href='file:///~/anaconda3/envs/torch/lib/python3.8/site-packages/pytorch_lightning/trainer/trainer.py?line=737'>738</a>\u001b[0m     )\n\u001b[1;32m    <a href='file:///~/anaconda3/envs/torch/lib/python3.8/site-packages/pytorch_lightning/trainer/trainer.py?line=738'>739</a>\u001b[0m     train_dataloaders \u001b[39m=\u001b[39m train_dataloader\n\u001b[0;32m--> <a href='file:///~/anaconda3/envs/torch/lib/python3.8/site-packages/pytorch_lightning/trainer/trainer.py?line=739'>740</a>\u001b[0m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_call_and_handle_interrupt(\n\u001b[1;32m    <a href='file:///~/anaconda3/envs/torch/lib/python3.8/site-packages/pytorch_lightning/trainer/trainer.py?line=740'>741</a>\u001b[0m     \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_fit_impl, model, train_dataloaders, val_dataloaders, datamodule, ckpt_path\n\u001b[1;32m    <a href='file:///~/anaconda3/envs/torch/lib/python3.8/site-packages/pytorch_lightning/trainer/trainer.py?line=741'>742</a>\u001b[0m )\n",
      "File \u001b[0;32m~/anaconda3/envs/torch/lib/python3.8/site-packages/pytorch_lightning/trainer/trainer.py:685\u001b[0m, in \u001b[0;36mTrainer._call_and_handle_interrupt\u001b[0;34m(self, trainer_fn, *args, **kwargs)\u001b[0m\n\u001b[1;32m    <a href='file:///~/anaconda3/envs/torch/lib/python3.8/site-packages/pytorch_lightning/trainer/trainer.py?line=674'>675</a>\u001b[0m \u001b[39mr\u001b[39m\u001b[39m\"\"\"\u001b[39;00m\n\u001b[1;32m    <a href='file:///~/anaconda3/envs/torch/lib/python3.8/site-packages/pytorch_lightning/trainer/trainer.py?line=675'>676</a>\u001b[0m \u001b[39mError handling, intended to be used only for main trainer function entry points (fit, validate, test, predict)\u001b[39;00m\n\u001b[1;32m    <a href='file:///~/anaconda3/envs/torch/lib/python3.8/site-packages/pytorch_lightning/trainer/trainer.py?line=676'>677</a>\u001b[0m \u001b[39mas all errors should funnel through them\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    <a href='file:///~/anaconda3/envs/torch/lib/python3.8/site-packages/pytorch_lightning/trainer/trainer.py?line=681'>682</a>\u001b[0m \u001b[39m    **kwargs: keyword arguments to be passed to `trainer_fn`\u001b[39;00m\n\u001b[1;32m    <a href='file:///~/anaconda3/envs/torch/lib/python3.8/site-packages/pytorch_lightning/trainer/trainer.py?line=682'>683</a>\u001b[0m \u001b[39m\"\"\"\u001b[39;00m\n\u001b[1;32m    <a href='file:///~/anaconda3/envs/torch/lib/python3.8/site-packages/pytorch_lightning/trainer/trainer.py?line=683'>684</a>\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[0;32m--> <a href='file:///~/anaconda3/envs/torch/lib/python3.8/site-packages/pytorch_lightning/trainer/trainer.py?line=684'>685</a>\u001b[0m     \u001b[39mreturn\u001b[39;00m trainer_fn(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[1;32m    <a href='file:///~/anaconda3/envs/torch/lib/python3.8/site-packages/pytorch_lightning/trainer/trainer.py?line=685'>686</a>\u001b[0m \u001b[39m# TODO: treat KeyboardInterrupt as BaseException (delete the code below) in v1.7\u001b[39;00m\n\u001b[1;32m    <a href='file:///~/anaconda3/envs/torch/lib/python3.8/site-packages/pytorch_lightning/trainer/trainer.py?line=686'>687</a>\u001b[0m \u001b[39mexcept\u001b[39;00m \u001b[39mKeyboardInterrupt\u001b[39;00m \u001b[39mas\u001b[39;00m exception:\n",
      "File \u001b[0;32m~/anaconda3/envs/torch/lib/python3.8/site-packages/pytorch_lightning/trainer/trainer.py:777\u001b[0m, in \u001b[0;36mTrainer._fit_impl\u001b[0;34m(self, model, train_dataloaders, val_dataloaders, datamodule, ckpt_path)\u001b[0m\n\u001b[1;32m    <a href='file:///~/anaconda3/envs/torch/lib/python3.8/site-packages/pytorch_lightning/trainer/trainer.py?line=774'>775</a>\u001b[0m \u001b[39m# TODO: ckpt_path only in v1.7\u001b[39;00m\n\u001b[1;32m    <a href='file:///~/anaconda3/envs/torch/lib/python3.8/site-packages/pytorch_lightning/trainer/trainer.py?line=775'>776</a>\u001b[0m ckpt_path \u001b[39m=\u001b[39m ckpt_path \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mresume_from_checkpoint\n\u001b[0;32m--> <a href='file:///~/anaconda3/envs/torch/lib/python3.8/site-packages/pytorch_lightning/trainer/trainer.py?line=776'>777</a>\u001b[0m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_run(model, ckpt_path\u001b[39m=\u001b[39;49mckpt_path)\n\u001b[1;32m    <a href='file:///~/anaconda3/envs/torch/lib/python3.8/site-packages/pytorch_lightning/trainer/trainer.py?line=778'>779</a>\u001b[0m \u001b[39massert\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mstate\u001b[39m.\u001b[39mstopped\n\u001b[1;32m    <a href='file:///~/anaconda3/envs/torch/lib/python3.8/site-packages/pytorch_lightning/trainer/trainer.py?line=779'>780</a>\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mtraining \u001b[39m=\u001b[39m \u001b[39mFalse\u001b[39;00m\n",
      "File \u001b[0;32m~/anaconda3/envs/torch/lib/python3.8/site-packages/pytorch_lightning/trainer/trainer.py:1188\u001b[0m, in \u001b[0;36mTrainer._run\u001b[0;34m(self, model, ckpt_path)\u001b[0m\n\u001b[1;32m   <a href='file:///~/anaconda3/envs/torch/lib/python3.8/site-packages/pytorch_lightning/trainer/trainer.py?line=1184'>1185</a>\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mcall_hook(\u001b[39m\"\u001b[39m\u001b[39mon_fit_start\u001b[39m\u001b[39m\"\u001b[39m)\n\u001b[1;32m   <a href='file:///~/anaconda3/envs/torch/lib/python3.8/site-packages/pytorch_lightning/trainer/trainer.py?line=1186'>1187</a>\u001b[0m \u001b[39m# plugin will setup fitting (e.g. ddp will launch child processes)\u001b[39;00m\n\u001b[0;32m-> <a href='file:///~/anaconda3/envs/torch/lib/python3.8/site-packages/pytorch_lightning/trainer/trainer.py?line=1187'>1188</a>\u001b[0m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_pre_dispatch()\n\u001b[1;32m   <a href='file:///~/anaconda3/envs/torch/lib/python3.8/site-packages/pytorch_lightning/trainer/trainer.py?line=1189'>1190</a>\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mtraining_type_plugin\u001b[39m.\u001b[39mrestore_checkpoint_after_pre_dispatch:\n\u001b[1;32m   <a href='file:///~/anaconda3/envs/torch/lib/python3.8/site-packages/pytorch_lightning/trainer/trainer.py?line=1190'>1191</a>\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_restore_modules_and_callbacks(ckpt_path)\n",
      "File \u001b[0;32m~/anaconda3/envs/torch/lib/python3.8/site-packages/pytorch_lightning/trainer/trainer.py:1224\u001b[0m, in \u001b[0;36mTrainer._pre_dispatch\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   <a href='file:///~/anaconda3/envs/torch/lib/python3.8/site-packages/pytorch_lightning/trainer/trainer.py?line=1221'>1222</a>\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39m_pre_dispatch\u001b[39m(\u001b[39mself\u001b[39m):\n\u001b[1;32m   <a href='file:///~/anaconda3/envs/torch/lib/python3.8/site-packages/pytorch_lightning/trainer/trainer.py?line=1222'>1223</a>\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39maccelerator\u001b[39m.\u001b[39mpre_dispatch(\u001b[39mself\u001b[39m)\n\u001b[0;32m-> <a href='file:///~/anaconda3/envs/torch/lib/python3.8/site-packages/pytorch_lightning/trainer/trainer.py?line=1223'>1224</a>\u001b[0m     \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_log_hyperparams()\n",
      "File \u001b[0;32m~/anaconda3/envs/torch/lib/python3.8/site-packages/pytorch_lightning/trainer/trainer.py:1260\u001b[0m, in \u001b[0;36mTrainer._log_hyperparams\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   <a href='file:///~/anaconda3/envs/torch/lib/python3.8/site-packages/pytorch_lightning/trainer/trainer.py?line=1257'>1258</a>\u001b[0m \u001b[39mif\u001b[39;00m hparams_initial \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[1;32m   <a href='file:///~/anaconda3/envs/torch/lib/python3.8/site-packages/pytorch_lightning/trainer/trainer.py?line=1258'>1259</a>\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mlogger\u001b[39m.\u001b[39mlog_hyperparams(hparams_initial)\n\u001b[0;32m-> <a href='file:///~/anaconda3/envs/torch/lib/python3.8/site-packages/pytorch_lightning/trainer/trainer.py?line=1259'>1260</a>\u001b[0m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mlogger\u001b[39m.\u001b[39;49mlog_graph(\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mlightning_module)\n\u001b[1;32m   <a href='file:///~/anaconda3/envs/torch/lib/python3.8/site-packages/pytorch_lightning/trainer/trainer.py?line=1260'>1261</a>\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mlogger\u001b[39m.\u001b[39msave()\n",
      "File \u001b[0;32m~/anaconda3/envs/torch/lib/python3.8/site-packages/pytorch_lightning/utilities/distributed.py:50\u001b[0m, in \u001b[0;36mrank_zero_only.<locals>.wrapped_fn\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     <a href='file:///~/anaconda3/envs/torch/lib/python3.8/site-packages/pytorch_lightning/utilities/distributed.py?line=46'>47</a>\u001b[0m \u001b[39m@wraps\u001b[39m(fn)\n\u001b[1;32m     <a href='file:///~/anaconda3/envs/torch/lib/python3.8/site-packages/pytorch_lightning/utilities/distributed.py?line=47'>48</a>\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mwrapped_fn\u001b[39m(\u001b[39m*\u001b[39margs: Any, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs: Any) \u001b[39m-\u001b[39m\u001b[39m>\u001b[39m Optional[Any]:\n\u001b[1;32m     <a href='file:///~/anaconda3/envs/torch/lib/python3.8/site-packages/pytorch_lightning/utilities/distributed.py?line=48'>49</a>\u001b[0m     \u001b[39mif\u001b[39;00m rank_zero_only\u001b[39m.\u001b[39mrank \u001b[39m==\u001b[39m \u001b[39m0\u001b[39m:\n\u001b[0;32m---> <a href='file:///~/anaconda3/envs/torch/lib/python3.8/site-packages/pytorch_lightning/utilities/distributed.py?line=49'>50</a>\u001b[0m         \u001b[39mreturn\u001b[39;00m fn(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[1;32m     <a href='file:///~/anaconda3/envs/torch/lib/python3.8/site-packages/pytorch_lightning/utilities/distributed.py?line=50'>51</a>\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mNone\u001b[39;00m\n",
      "File \u001b[0;32m~/anaconda3/envs/torch/lib/python3.8/site-packages/pytorch_lightning/loggers/tensorboard.py:244\u001b[0m, in \u001b[0;36mTensorBoardLogger.log_graph\u001b[0;34m(self, model, input_array)\u001b[0m\n\u001b[1;32m    <a href='file:///~/anaconda3/envs/torch/lib/python3.8/site-packages/pytorch_lightning/loggers/tensorboard.py?line=241'>242</a>\u001b[0m     input_array \u001b[39m=\u001b[39m model\u001b[39m.\u001b[39m_apply_batch_transfer_handler(input_array)\n\u001b[1;32m    <a href='file:///~/anaconda3/envs/torch/lib/python3.8/site-packages/pytorch_lightning/loggers/tensorboard.py?line=242'>243</a>\u001b[0m     model\u001b[39m.\u001b[39m_running_torchscript \u001b[39m=\u001b[39m \u001b[39mTrue\u001b[39;00m\n\u001b[0;32m--> <a href='file:///~/anaconda3/envs/torch/lib/python3.8/site-packages/pytorch_lightning/loggers/tensorboard.py?line=243'>244</a>\u001b[0m     \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mexperiment\u001b[39m.\u001b[39;49madd_graph(model, input_array)\n\u001b[1;32m    <a href='file:///~/anaconda3/envs/torch/lib/python3.8/site-packages/pytorch_lightning/loggers/tensorboard.py?line=244'>245</a>\u001b[0m     model\u001b[39m.\u001b[39m_running_torchscript \u001b[39m=\u001b[39m \u001b[39mFalse\u001b[39;00m\n\u001b[1;32m    <a href='file:///~/anaconda3/envs/torch/lib/python3.8/site-packages/pytorch_lightning/loggers/tensorboard.py?line=245'>246</a>\u001b[0m \u001b[39melse\u001b[39;00m:\n",
      "File \u001b[0;32m~/anaconda3/envs/torch/lib/python3.8/site-packages/torch/utils/tensorboard/writer.py:736\u001b[0m, in \u001b[0;36mSummaryWriter.add_graph\u001b[0;34m(self, model, input_to_model, verbose, use_strict_trace)\u001b[0m\n\u001b[1;32m    <a href='file:///~/anaconda3/envs/torch/lib/python3.8/site-packages/torch/utils/tensorboard/writer.py?line=732'>733</a>\u001b[0m torch\u001b[39m.\u001b[39m_C\u001b[39m.\u001b[39m_log_api_usage_once(\u001b[39m\"\u001b[39m\u001b[39mtensorboard.logging.add_graph\u001b[39m\u001b[39m\"\u001b[39m)\n\u001b[1;32m    <a href='file:///~/anaconda3/envs/torch/lib/python3.8/site-packages/torch/utils/tensorboard/writer.py?line=733'>734</a>\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mhasattr\u001b[39m(model, \u001b[39m'\u001b[39m\u001b[39mforward\u001b[39m\u001b[39m'\u001b[39m):\n\u001b[1;32m    <a href='file:///~/anaconda3/envs/torch/lib/python3.8/site-packages/torch/utils/tensorboard/writer.py?line=734'>735</a>\u001b[0m     \u001b[39m# A valid PyTorch model should have a 'forward' method\u001b[39;00m\n\u001b[0;32m--> <a href='file:///~/anaconda3/envs/torch/lib/python3.8/site-packages/torch/utils/tensorboard/writer.py?line=735'>736</a>\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_get_file_writer()\u001b[39m.\u001b[39madd_graph(graph(model, input_to_model, verbose, use_strict_trace))\n\u001b[1;32m    <a href='file:///~/anaconda3/envs/torch/lib/python3.8/site-packages/torch/utils/tensorboard/writer.py?line=736'>737</a>\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[1;32m    <a href='file:///~/anaconda3/envs/torch/lib/python3.8/site-packages/torch/utils/tensorboard/writer.py?line=737'>738</a>\u001b[0m     \u001b[39m# Caffe2 models do not have the 'forward' method\u001b[39;00m\n\u001b[1;32m    <a href='file:///~/anaconda3/envs/torch/lib/python3.8/site-packages/torch/utils/tensorboard/writer.py?line=738'>739</a>\u001b[0m     \u001b[39mfrom\u001b[39;00m \u001b[39mcaffe2\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mproto\u001b[39;00m \u001b[39mimport\u001b[39;00m caffe2_pb2\n",
      "File \u001b[0;32m~/anaconda3/envs/torch/lib/python3.8/site-packages/torch/utils/tensorboard/_pytorch_graph.py:295\u001b[0m, in \u001b[0;36mgraph\u001b[0;34m(model, args, verbose, use_strict_trace)\u001b[0m\n\u001b[1;32m    <a href='file:///~/anaconda3/envs/torch/lib/python3.8/site-packages/torch/utils/tensorboard/_pytorch_graph.py?line=292'>293</a>\u001b[0m         \u001b[39mprint\u001b[39m(e)\n\u001b[1;32m    <a href='file:///~/anaconda3/envs/torch/lib/python3.8/site-packages/torch/utils/tensorboard/_pytorch_graph.py?line=293'>294</a>\u001b[0m         \u001b[39mprint\u001b[39m(\u001b[39m'\u001b[39m\u001b[39mError occurs, No graph saved\u001b[39m\u001b[39m'\u001b[39m)\n\u001b[0;32m--> <a href='file:///~/anaconda3/envs/torch/lib/python3.8/site-packages/torch/utils/tensorboard/_pytorch_graph.py?line=294'>295</a>\u001b[0m         \u001b[39mraise\u001b[39;00m e\n\u001b[1;32m    <a href='file:///~/anaconda3/envs/torch/lib/python3.8/site-packages/torch/utils/tensorboard/_pytorch_graph.py?line=296'>297</a>\u001b[0m \u001b[39mif\u001b[39;00m verbose:\n\u001b[1;32m    <a href='file:///~/anaconda3/envs/torch/lib/python3.8/site-packages/torch/utils/tensorboard/_pytorch_graph.py?line=297'>298</a>\u001b[0m     \u001b[39mprint\u001b[39m(graph)\n",
      "File \u001b[0;32m~/anaconda3/envs/torch/lib/python3.8/site-packages/torch/utils/tensorboard/_pytorch_graph.py:289\u001b[0m, in \u001b[0;36mgraph\u001b[0;34m(model, args, verbose, use_strict_trace)\u001b[0m\n\u001b[1;32m    <a href='file:///~/anaconda3/envs/torch/lib/python3.8/site-packages/torch/utils/tensorboard/_pytorch_graph.py?line=286'>287</a>\u001b[0m \u001b[39mwith\u001b[39;00m torch\u001b[39m.\u001b[39monnx\u001b[39m.\u001b[39mselect_model_mode_for_export(model, torch\u001b[39m.\u001b[39monnx\u001b[39m.\u001b[39mTrainingMode\u001b[39m.\u001b[39mEVAL):  \u001b[39m# TODO: move outside of torch.onnx?\u001b[39;00m\n\u001b[1;32m    <a href='file:///~/anaconda3/envs/torch/lib/python3.8/site-packages/torch/utils/tensorboard/_pytorch_graph.py?line=287'>288</a>\u001b[0m     \u001b[39mtry\u001b[39;00m:\n\u001b[0;32m--> <a href='file:///~/anaconda3/envs/torch/lib/python3.8/site-packages/torch/utils/tensorboard/_pytorch_graph.py?line=288'>289</a>\u001b[0m         trace \u001b[39m=\u001b[39m torch\u001b[39m.\u001b[39;49mjit\u001b[39m.\u001b[39;49mtrace(model, args, strict\u001b[39m=\u001b[39;49muse_strict_trace)\n\u001b[1;32m    <a href='file:///~/anaconda3/envs/torch/lib/python3.8/site-packages/torch/utils/tensorboard/_pytorch_graph.py?line=289'>290</a>\u001b[0m         graph \u001b[39m=\u001b[39m trace\u001b[39m.\u001b[39mgraph\n\u001b[1;32m    <a href='file:///~/anaconda3/envs/torch/lib/python3.8/site-packages/torch/utils/tensorboard/_pytorch_graph.py?line=290'>291</a>\u001b[0m         torch\u001b[39m.\u001b[39m_C\u001b[39m.\u001b[39m_jit_pass_inline(graph)\n",
      "File \u001b[0;32m~/anaconda3/envs/torch/lib/python3.8/site-packages/torch/jit/_trace.py:741\u001b[0m, in \u001b[0;36mtrace\u001b[0;34m(func, example_inputs, optimize, check_trace, check_inputs, check_tolerance, strict, _force_outplace, _module_class, _compilation_unit)\u001b[0m\n\u001b[1;32m    <a href='file:///~/anaconda3/envs/torch/lib/python3.8/site-packages/torch/jit/_trace.py?line=737'>738</a>\u001b[0m     \u001b[39mreturn\u001b[39;00m func\n\u001b[1;32m    <a href='file:///~/anaconda3/envs/torch/lib/python3.8/site-packages/torch/jit/_trace.py?line=739'>740</a>\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39misinstance\u001b[39m(func, torch\u001b[39m.\u001b[39mnn\u001b[39m.\u001b[39mModule):\n\u001b[0;32m--> <a href='file:///~/anaconda3/envs/torch/lib/python3.8/site-packages/torch/jit/_trace.py?line=740'>741</a>\u001b[0m     \u001b[39mreturn\u001b[39;00m trace_module(\n\u001b[1;32m    <a href='file:///~/anaconda3/envs/torch/lib/python3.8/site-packages/torch/jit/_trace.py?line=741'>742</a>\u001b[0m         func,\n\u001b[1;32m    <a href='file:///~/anaconda3/envs/torch/lib/python3.8/site-packages/torch/jit/_trace.py?line=742'>743</a>\u001b[0m         {\u001b[39m\"\u001b[39;49m\u001b[39mforward\u001b[39;49m\u001b[39m\"\u001b[39;49m: example_inputs},\n\u001b[1;32m    <a href='file:///~/anaconda3/envs/torch/lib/python3.8/site-packages/torch/jit/_trace.py?line=743'>744</a>\u001b[0m         \u001b[39mNone\u001b[39;49;00m,\n\u001b[1;32m    <a href='file:///~/anaconda3/envs/torch/lib/python3.8/site-packages/torch/jit/_trace.py?line=744'>745</a>\u001b[0m         check_trace,\n\u001b[1;32m    <a href='file:///~/anaconda3/envs/torch/lib/python3.8/site-packages/torch/jit/_trace.py?line=745'>746</a>\u001b[0m         wrap_check_inputs(check_inputs),\n\u001b[1;32m    <a href='file:///~/anaconda3/envs/torch/lib/python3.8/site-packages/torch/jit/_trace.py?line=746'>747</a>\u001b[0m         check_tolerance,\n\u001b[1;32m    <a href='file:///~/anaconda3/envs/torch/lib/python3.8/site-packages/torch/jit/_trace.py?line=747'>748</a>\u001b[0m         strict,\n\u001b[1;32m    <a href='file:///~/anaconda3/envs/torch/lib/python3.8/site-packages/torch/jit/_trace.py?line=748'>749</a>\u001b[0m         _force_outplace,\n\u001b[1;32m    <a href='file:///~/anaconda3/envs/torch/lib/python3.8/site-packages/torch/jit/_trace.py?line=749'>750</a>\u001b[0m         _module_class,\n\u001b[1;32m    <a href='file:///~/anaconda3/envs/torch/lib/python3.8/site-packages/torch/jit/_trace.py?line=750'>751</a>\u001b[0m     )\n\u001b[1;32m    <a href='file:///~/anaconda3/envs/torch/lib/python3.8/site-packages/torch/jit/_trace.py?line=752'>753</a>\u001b[0m \u001b[39mif\u001b[39;00m (\n\u001b[1;32m    <a href='file:///~/anaconda3/envs/torch/lib/python3.8/site-packages/torch/jit/_trace.py?line=753'>754</a>\u001b[0m     \u001b[39mhasattr\u001b[39m(func, \u001b[39m\"\u001b[39m\u001b[39m__self__\u001b[39m\u001b[39m\"\u001b[39m)\n\u001b[1;32m    <a href='file:///~/anaconda3/envs/torch/lib/python3.8/site-packages/torch/jit/_trace.py?line=754'>755</a>\u001b[0m     \u001b[39mand\u001b[39;00m \u001b[39misinstance\u001b[39m(func\u001b[39m.\u001b[39m\u001b[39m__self__\u001b[39m, torch\u001b[39m.\u001b[39mnn\u001b[39m.\u001b[39mModule)\n\u001b[1;32m    <a href='file:///~/anaconda3/envs/torch/lib/python3.8/site-packages/torch/jit/_trace.py?line=755'>756</a>\u001b[0m     \u001b[39mand\u001b[39;00m func\u001b[39m.\u001b[39m\u001b[39m__name__\u001b[39m \u001b[39m==\u001b[39m \u001b[39m\"\u001b[39m\u001b[39mforward\u001b[39m\u001b[39m\"\u001b[39m\n\u001b[1;32m    <a href='file:///~/anaconda3/envs/torch/lib/python3.8/site-packages/torch/jit/_trace.py?line=756'>757</a>\u001b[0m ):\n\u001b[1;32m    <a href='file:///~/anaconda3/envs/torch/lib/python3.8/site-packages/torch/jit/_trace.py?line=757'>758</a>\u001b[0m     \u001b[39mreturn\u001b[39;00m trace_module(\n\u001b[1;32m    <a href='file:///~/anaconda3/envs/torch/lib/python3.8/site-packages/torch/jit/_trace.py?line=758'>759</a>\u001b[0m         func\u001b[39m.\u001b[39m\u001b[39m__self__\u001b[39m,\n\u001b[1;32m    <a href='file:///~/anaconda3/envs/torch/lib/python3.8/site-packages/torch/jit/_trace.py?line=759'>760</a>\u001b[0m         {\u001b[39m\"\u001b[39m\u001b[39mforward\u001b[39m\u001b[39m\"\u001b[39m: example_inputs},\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    <a href='file:///~/anaconda3/envs/torch/lib/python3.8/site-packages/torch/jit/_trace.py?line=766'>767</a>\u001b[0m         _module_class,\n\u001b[1;32m    <a href='file:///~/anaconda3/envs/torch/lib/python3.8/site-packages/torch/jit/_trace.py?line=767'>768</a>\u001b[0m     )\n",
      "File \u001b[0;32m~/anaconda3/envs/torch/lib/python3.8/site-packages/torch/jit/_trace.py:958\u001b[0m, in \u001b[0;36mtrace_module\u001b[0;34m(mod, inputs, optimize, check_trace, check_inputs, check_tolerance, strict, _force_outplace, _module_class, _compilation_unit)\u001b[0m\n\u001b[1;32m    <a href='file:///~/anaconda3/envs/torch/lib/python3.8/site-packages/torch/jit/_trace.py?line=953'>954</a>\u001b[0m     argument_names \u001b[39m=\u001b[39m get_callable_argument_names(func)\n\u001b[1;32m    <a href='file:///~/anaconda3/envs/torch/lib/python3.8/site-packages/torch/jit/_trace.py?line=955'>956</a>\u001b[0m example_inputs \u001b[39m=\u001b[39m make_tuple(example_inputs)\n\u001b[0;32m--> <a href='file:///~/anaconda3/envs/torch/lib/python3.8/site-packages/torch/jit/_trace.py?line=957'>958</a>\u001b[0m module\u001b[39m.\u001b[39;49m_c\u001b[39m.\u001b[39;49m_create_method_from_trace(\n\u001b[1;32m    <a href='file:///~/anaconda3/envs/torch/lib/python3.8/site-packages/torch/jit/_trace.py?line=958'>959</a>\u001b[0m     method_name,\n\u001b[1;32m    <a href='file:///~/anaconda3/envs/torch/lib/python3.8/site-packages/torch/jit/_trace.py?line=959'>960</a>\u001b[0m     func,\n\u001b[1;32m    <a href='file:///~/anaconda3/envs/torch/lib/python3.8/site-packages/torch/jit/_trace.py?line=960'>961</a>\u001b[0m     example_inputs,\n\u001b[1;32m    <a href='file:///~/anaconda3/envs/torch/lib/python3.8/site-packages/torch/jit/_trace.py?line=961'>962</a>\u001b[0m     var_lookup_fn,\n\u001b[1;32m    <a href='file:///~/anaconda3/envs/torch/lib/python3.8/site-packages/torch/jit/_trace.py?line=962'>963</a>\u001b[0m     strict,\n\u001b[1;32m    <a href='file:///~/anaconda3/envs/torch/lib/python3.8/site-packages/torch/jit/_trace.py?line=963'>964</a>\u001b[0m     _force_outplace,\n\u001b[1;32m    <a href='file:///~/anaconda3/envs/torch/lib/python3.8/site-packages/torch/jit/_trace.py?line=964'>965</a>\u001b[0m     argument_names,\n\u001b[1;32m    <a href='file:///~/anaconda3/envs/torch/lib/python3.8/site-packages/torch/jit/_trace.py?line=965'>966</a>\u001b[0m )\n\u001b[1;32m    <a href='file:///~/anaconda3/envs/torch/lib/python3.8/site-packages/torch/jit/_trace.py?line=966'>967</a>\u001b[0m check_trace_method \u001b[39m=\u001b[39m module\u001b[39m.\u001b[39m_c\u001b[39m.\u001b[39m_get_method(method_name)\n\u001b[1;32m    <a href='file:///~/anaconda3/envs/torch/lib/python3.8/site-packages/torch/jit/_trace.py?line=968'>969</a>\u001b[0m \u001b[39m# Check the trace against new traces created from user-specified inputs\u001b[39;00m\n",
      "File \u001b[0;32m~/anaconda3/envs/torch/lib/python3.8/site-packages/torch/nn/modules/module.py:1102\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m   <a href='file:///~/anaconda3/envs/torch/lib/python3.8/site-packages/torch/nn/modules/module.py?line=1097'>1098</a>\u001b[0m \u001b[39m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   <a href='file:///~/anaconda3/envs/torch/lib/python3.8/site-packages/torch/nn/modules/module.py?line=1098'>1099</a>\u001b[0m \u001b[39m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   <a href='file:///~/anaconda3/envs/torch/lib/python3.8/site-packages/torch/nn/modules/module.py?line=1099'>1100</a>\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m (\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_pre_hooks \u001b[39mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   <a href='file:///~/anaconda3/envs/torch/lib/python3.8/site-packages/torch/nn/modules/module.py?line=1100'>1101</a>\u001b[0m         \u001b[39mor\u001b[39;00m _global_forward_hooks \u001b[39mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> <a href='file:///~/anaconda3/envs/torch/lib/python3.8/site-packages/torch/nn/modules/module.py?line=1101'>1102</a>\u001b[0m     \u001b[39mreturn\u001b[39;00m forward_call(\u001b[39m*\u001b[39;49m\u001b[39minput\u001b[39;49m, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[1;32m   <a href='file:///~/anaconda3/envs/torch/lib/python3.8/site-packages/torch/nn/modules/module.py?line=1102'>1103</a>\u001b[0m \u001b[39m# Do not call functions when jit is used\u001b[39;00m\n\u001b[1;32m   <a href='file:///~/anaconda3/envs/torch/lib/python3.8/site-packages/torch/nn/modules/module.py?line=1103'>1104</a>\u001b[0m full_backward_hooks, non_full_backward_hooks \u001b[39m=\u001b[39m [], []\n",
      "File \u001b[0;32m~/anaconda3/envs/torch/lib/python3.8/site-packages/torch/nn/modules/module.py:1090\u001b[0m, in \u001b[0;36mModule._slow_forward\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m   <a href='file:///~/anaconda3/envs/torch/lib/python3.8/site-packages/torch/nn/modules/module.py?line=1087'>1088</a>\u001b[0m         recording_scopes \u001b[39m=\u001b[39m \u001b[39mFalse\u001b[39;00m\n\u001b[1;32m   <a href='file:///~/anaconda3/envs/torch/lib/python3.8/site-packages/torch/nn/modules/module.py?line=1088'>1089</a>\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[0;32m-> <a href='file:///~/anaconda3/envs/torch/lib/python3.8/site-packages/torch/nn/modules/module.py?line=1089'>1090</a>\u001b[0m     result \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mforward(\u001b[39m*\u001b[39;49m\u001b[39minput\u001b[39;49m, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[1;32m   <a href='file:///~/anaconda3/envs/torch/lib/python3.8/site-packages/torch/nn/modules/module.py?line=1090'>1091</a>\u001b[0m \u001b[39mfinally\u001b[39;00m:\n\u001b[1;32m   <a href='file:///~/anaconda3/envs/torch/lib/python3.8/site-packages/torch/nn/modules/module.py?line=1091'>1092</a>\u001b[0m     \u001b[39mif\u001b[39;00m recording_scopes:\n",
      "File \u001b[0;32m~/React_Net/model.py:90\u001b[0m, in \u001b[0;36mBaselineModel.forward\u001b[0;34m(self, x)\u001b[0m\n\u001b[1;32m     <a href='file:///~/React_Net/model.py?line=88'>89</a>\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mforward\u001b[39m(\u001b[39mself\u001b[39m, x):\n\u001b[0;32m---> <a href='file:///~/React_Net/model.py?line=89'>90</a>\u001b[0m     y \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mbase_block(x)\n\u001b[1;32m     <a href='file:///~/React_Net/model.py?line=90'>91</a>\u001b[0m     \u001b[39mreturn\u001b[39;00m F\u001b[39m.\u001b[39mlog_softmax(y\u001b[39m.\u001b[39msqueeze(dim\u001b[39m=\u001b[39m\u001b[39m2\u001b[39m)\u001b[39m.\u001b[39msqueeze(dim\u001b[39m=\u001b[39m\u001b[39m2\u001b[39m), dim\u001b[39m=\u001b[39m\u001b[39m1\u001b[39m)\n",
      "File \u001b[0;32m~/anaconda3/envs/torch/lib/python3.8/site-packages/torch/nn/modules/module.py:1102\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m   <a href='file:///~/anaconda3/envs/torch/lib/python3.8/site-packages/torch/nn/modules/module.py?line=1097'>1098</a>\u001b[0m \u001b[39m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   <a href='file:///~/anaconda3/envs/torch/lib/python3.8/site-packages/torch/nn/modules/module.py?line=1098'>1099</a>\u001b[0m \u001b[39m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   <a href='file:///~/anaconda3/envs/torch/lib/python3.8/site-packages/torch/nn/modules/module.py?line=1099'>1100</a>\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m (\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_pre_hooks \u001b[39mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   <a href='file:///~/anaconda3/envs/torch/lib/python3.8/site-packages/torch/nn/modules/module.py?line=1100'>1101</a>\u001b[0m         \u001b[39mor\u001b[39;00m _global_forward_hooks \u001b[39mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> <a href='file:///~/anaconda3/envs/torch/lib/python3.8/site-packages/torch/nn/modules/module.py?line=1101'>1102</a>\u001b[0m     \u001b[39mreturn\u001b[39;00m forward_call(\u001b[39m*\u001b[39;49m\u001b[39minput\u001b[39;49m, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[1;32m   <a href='file:///~/anaconda3/envs/torch/lib/python3.8/site-packages/torch/nn/modules/module.py?line=1102'>1103</a>\u001b[0m \u001b[39m# Do not call functions when jit is used\u001b[39;00m\n\u001b[1;32m   <a href='file:///~/anaconda3/envs/torch/lib/python3.8/site-packages/torch/nn/modules/module.py?line=1103'>1104</a>\u001b[0m full_backward_hooks, non_full_backward_hooks \u001b[39m=\u001b[39m [], []\n",
      "File \u001b[0;32m~/anaconda3/envs/torch/lib/python3.8/site-packages/torch/nn/modules/module.py:1090\u001b[0m, in \u001b[0;36mModule._slow_forward\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m   <a href='file:///~/anaconda3/envs/torch/lib/python3.8/site-packages/torch/nn/modules/module.py?line=1087'>1088</a>\u001b[0m         recording_scopes \u001b[39m=\u001b[39m \u001b[39mFalse\u001b[39;00m\n\u001b[1;32m   <a href='file:///~/anaconda3/envs/torch/lib/python3.8/site-packages/torch/nn/modules/module.py?line=1088'>1089</a>\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[0;32m-> <a href='file:///~/anaconda3/envs/torch/lib/python3.8/site-packages/torch/nn/modules/module.py?line=1089'>1090</a>\u001b[0m     result \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mforward(\u001b[39m*\u001b[39;49m\u001b[39minput\u001b[39;49m, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[1;32m   <a href='file:///~/anaconda3/envs/torch/lib/python3.8/site-packages/torch/nn/modules/module.py?line=1090'>1091</a>\u001b[0m \u001b[39mfinally\u001b[39;00m:\n\u001b[1;32m   <a href='file:///~/anaconda3/envs/torch/lib/python3.8/site-packages/torch/nn/modules/module.py?line=1091'>1092</a>\u001b[0m     \u001b[39mif\u001b[39;00m recording_scopes:\n",
      "File \u001b[0;32m~/anaconda3/envs/torch/lib/python3.8/site-packages/torch/nn/modules/module.py:201\u001b[0m, in \u001b[0;36m_forward_unimplemented\u001b[0;34m(self, *input)\u001b[0m\n\u001b[1;32m    <a href='file:///~/anaconda3/envs/torch/lib/python3.8/site-packages/torch/nn/modules/module.py?line=189'>190</a>\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39m_forward_unimplemented\u001b[39m(\u001b[39mself\u001b[39m, \u001b[39m*\u001b[39m\u001b[39minput\u001b[39m: Any) \u001b[39m-\u001b[39m\u001b[39m>\u001b[39m \u001b[39mNone\u001b[39;00m:\n\u001b[1;32m    <a href='file:///~/anaconda3/envs/torch/lib/python3.8/site-packages/torch/nn/modules/module.py?line=190'>191</a>\u001b[0m     \u001b[39mr\u001b[39m\u001b[39m\"\"\"Defines the computation performed at every call.\u001b[39;00m\n\u001b[1;32m    <a href='file:///~/anaconda3/envs/torch/lib/python3.8/site-packages/torch/nn/modules/module.py?line=191'>192</a>\u001b[0m \n\u001b[1;32m    <a href='file:///~/anaconda3/envs/torch/lib/python3.8/site-packages/torch/nn/modules/module.py?line=192'>193</a>\u001b[0m \u001b[39m    Should be overridden by all subclasses.\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    <a href='file:///~/anaconda3/envs/torch/lib/python3.8/site-packages/torch/nn/modules/module.py?line=198'>199</a>\u001b[0m \u001b[39m        registered hooks while the latter silently ignores them.\u001b[39;00m\n\u001b[1;32m    <a href='file:///~/anaconda3/envs/torch/lib/python3.8/site-packages/torch/nn/modules/module.py?line=199'>200</a>\u001b[0m \u001b[39m    \"\"\"\u001b[39;00m\n\u001b[0;32m--> <a href='file:///~/anaconda3/envs/torch/lib/python3.8/site-packages/torch/nn/modules/module.py?line=200'>201</a>\u001b[0m     \u001b[39mraise\u001b[39;00m \u001b[39mNotImplementedError\u001b[39;00m\n",
      "\u001b[0;31mNotImplementedError\u001b[0m: "
     ]
    }
   ],
   "source": [
    "from pytorch_lightning import Trainer\n",
    "from pytorch_lightning.callbacks import LearningRateMonitor\n",
    "from pytorch_lightning.callbacks import EarlyStopping\n",
    "from pytorch_lightning.callbacks.model_checkpoint import ModelCheckpoint\n",
    "from pytorch_lightning.loggers import TensorBoardLogger\n",
    "\n",
    "checkpoint_callback = ModelCheckpoint(filename='{epoch}-{val_loss:.4f}-{val_acc:.4f}', monitor='val_acc', mode='max')\n",
    "trainer = Trainer(\n",
    "    max_epochs=-1,\n",
    "    gpus=AVAIL_GPUS,\n",
    "    logger=TensorBoardLogger('lightning_logs/', name='ReActNet', log_graph=True),\n",
    "    # logger=TensorBoardLogger('lightning_logs/', name='Real', log_graph=True),\n",
    "    callbacks=[LearningRateMonitor(logging_interval='step'), \n",
    "               EarlyStopping(monitor='val_acc', mode='max', patience=100),\n",
    "               checkpoint_callback],\n",
    "    deterministic=True,\n",
    "#    gradient_clip_val = 0.5\n",
    ")\n",
    "\n",
    "trainer.fit(base_model, datamodule=cifar10_dm)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "47e09afa00117adb128a14bba5a0354c21242f9789155299d9b4cfecff478770"
  },
  "kernelspec": {
   "display_name": "Python 3.8.12 ('torch')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.12"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
